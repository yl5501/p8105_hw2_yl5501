---
title: "Homework 2"
author: Yujie Li
date: 2024-09-30
output: github_document 
---


```{r, echo = FALSE, message = FALSE}
library(tidyverse)
library(janitor)
library(readr)
library(tidyr)
```


## Problem 1 
```{r}
nyc_ts= 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv", show_col_types = FALSE) %>%
  janitor::clean_names() |> 
  select(line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, 
         entry, vending, entrance_type, ada) %>%
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))

nyc_ts
```

## This dataset contains varibales as followed: line, station_name, station_latitude, station_longitude, route1, route2,  route3, route4, route5, entry, vending, entrance_type, and ada. 
## I used "select" to clean the data by retaining the relevant columns and "mutate" to convert the 'entry' variable with "YES" and "NO" into a logical format (TRUE/FALSE). 
## The dimension of the resulting dataset is 1868 x 13 (rows x columns). 
## These data are relatively tidy comparing to the original one, but the routes served could be further tidied (there are too many columns for routes).

```{r}
# Number of distinct stations (identified by both station name and line)
distinct_stations <- nyc_ts %>%
  distinct(station_name, line) %>%
  count()

# Number of ADA compliant stations
ada_compliant_stations <- nyc_ts %>%
  filter(ada == TRUE) %>%
  distinct(station_name, line) %>%
  count()

# Proportion of entrances/exits without vending that allow entrance
proportion_without_vending_allow_entry <- nyc_ts %>%
  filter(vending == "NO") %>%
  summarise(proportion = mean(entry))

distinct_stations
ada_compliant_stations
proportion_without_vending_allow_entry
```

## There are 465 distinct stations. 
## 84 stations are ADA compliant.
## About 37.7% of station entries/exits without vending allow entrance. 

## Reformat
```{r}
nyc_ts_long <- nyc_ts %>%
  pivot_longer(
    cols = starts_with("route"),   # Pivot route1, route2, route3, etc.
    names_to = "route_number",     # Name of the new column for route numbers
    values_to = "route"            # Name of the new column for route names
  ) %>%
  filter(!is.na(route))  # Remove rows with NA routes
```

```{r}
stations_a_train <- nyc_ts_long %>%
  filter(route == "A") %>%
  distinct(station_name, line) %>%
  count()

ada_compliant_a_train <- nyc_ts_long %>%
  filter(route == "A", ada == TRUE) %>%
  distinct(station_name, line) %>%
  count()

stations_a_train
ada_compliant_a_train
```

## 60 distinct stations serve the A train.
## 17 of those are ADA compliant.


## Problem 2
```{r}
mr_trash_wheel = 
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel") |> 
  clean_names() |>  
  filter(!is.na(dumpster)) |>  
  mutate(sports_balls = as.integer(round(sports_balls, 0)))  
 trash_wheel = "Mr. Trash Wheel"
mr_trash_wheel
```


```{r}
prof_trash_wheel = 
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel") |> 
  clean_names() |> 
  filter(!is.na(dumpster)) |>  
  mutate(
    sports_balls = NA_integer_,
    trash_wheel = "Professor Trash Wheel" 
  )
prof_trash_wheel
```


```{r}
gwynnda_trash_wheel =  
  readxl::read_excel("data/202309 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel") |> 
  clean_names() |> 
  filter(!is.na(dumpster)) |> 
  mutate(
    sports_balls =  NA_integer_,  
    trash_wheel = "Gwynnda Trash Wheel"  
  )
gwynnda_trash_wheel
```


```{r}
combined_data <- mr_trash_wheel %>%
  left_join(prof_trash_wheel, by = "dumpster") %>%
  left_join(gwynnda_trash_wheel, by = "dumpster")
combined_data
```
## There are 585 observations in the combined dataset. 



```{r}
combined_data <- combined_data %>%
  mutate(trash_wheel = str_trim(trash_wheel)) 
```



```{r}
# Total weight of trash collected by Professor Trash Wheel
total_weight_professor <- combined_data %>%
  filter(trash_wheel == "Professor Trash Wheel") %>%
  summarise(total_weight = sum(weight_tons, na.rm = TRUE))

total_weight_professor$total_weight

# Total number of cigarette butts collected by Gwynnda in June 2022
cig_butts_gwynnda_june <- combined_data %>%
  filter(trash_wheel == "Gwynnda Trash Wheel", month == "June", year == 2022) %>%
  summarise(total_cig_butts = sum(cigarette_butts, na.rm = TRUE))

cig_butts_gwynnda_june$total_cig_butts
```



## Problem 3
```{r}
bakers_df = 
  read_csv(
    "data/bakers.csv",
    na = c("NA", "", ".")) |>
  janitor::clean_names() |>
separate (baker_name, into = c ("baker", "last_name"), sep = " ")
bakers_df
```


```{r}
bakes_df = 
  read_csv(
    "data/bakes.csv",
    na = c("NA", "", ".")) |>
  janitor::clean_names() 

bakes_df
```

```{r}
results_df = 
  read_csv(
    "data/results.csv",
    na = c("NA", "", "."), skip = 2) |>
  janitor::clean_names() 

results_df
```


```{r}
viewers_df = 
  read_csv(
    "data/viewers.csv",
    na = c("NA", "", ".")) |>
  janitor::clean_names() 
viewers_df
```


```{r}
bakers_df <- bakers_df %>%
  mutate(baker = str_trim(tolower(baker)))

results_df <- results_df %>%
  mutate(baker = str_trim(tolower(baker)))

bakes_df <- bakes_df %>%
  mutate(baker = str_trim(tolower(baker)))

bakers_df
results_df
bakes_df
```





```{r}
unmatched_bakers_in_results =
  anti_join(results_df, bakers_df, by = "baker")
unmatched_bakers_in_results
```

```{r}
unmatched_bakers_in_bakes =
  anti_join(bakes_df, bakers_df, by = "baker", "seasons")
unmatched_bakers_in_bakes


bakes_df <- bakes_df %>%
  rename(series = season)
bakes_df
```

```{r}
# Merge bakers_df with results_df by baker and series
combined_data <- bakers_df %>%
  left_join(results_df, by = c("baker", "series"))

# Merge the combined dataset with bakes_df by baker, series, and episode
final_combined_data <- combined_data %>%
  left_join(bakes_df, by = c("baker", "series", "episode"))
final_combined_data
```


```{r}
write_csv(final_combined_data, "data/final_combined_gbbo.csv")
```

## Describe the data cleaning process:
After importing the csv file, I eliminate unmeaningful rows in results file. For consistency among the 4 datasets, I decide to seperate the baker_name column in bakes file into baker and last_name. 
A question I have is what the optimal way is to deal with the N/A value for techincal and result column.
The final dataset includes the baker's first name, last name, age, hometown, occupation, series and results from each episodes including the technical rankings.  



## Create a table for Star Baker / winner
```{r}
unique(combined_data$result)
```


```{r}
combined_data <- combined_data %>%
  mutate(result = str_trim(tolower(result)))

star_bakers <- combined_data %>%
  filter(series >= 5 & series <= 10, result %in% c("Star Baker", "winner")) %>%
  select(series, episode, baker, result) %>%
  arrange(series, episode)
star_bakers
```
## Comment on the table above:
Predictable overall winners - Nadiya and Rahul.
Suprises - David (not a star baker until the finale)


## Import, clean, tidy, and organize the viewership data in viewers.csv

```{r}
library(dplyr)
library(readr)
```

```{r}
viewers_df =
  read_csv("data/viewers.csv") |> 
  janitor::clean_names()  

viewers_df %>% 
  head(10) #Showing the first 10 rows. 
```
```{r}
viewers_long_df <- viewers_df %>%
  pivot_longer(cols = starts_with("series_"), 
               names_to = "series", 
               values_to = "viewership") %>%
  mutate(series = as.numeric(gsub("series_", "", series)))  

average_viewership_s1 <- viewers_long_df %>%
  filter(series == 1) %>%
  summarize(avg_viewership = mean(viewership, na.rm = TRUE))

average_viewership_s5 <- viewers_long_df %>%
  filter(series == 5) %>%
  summarize(avg_viewership = mean(viewership, na.rm = TRUE))


average_viewership_s1
average_viewership_s5

```
## The average viewership in season 1 is 2.77.
## The average viewership in season 5 is 10.0393. 

